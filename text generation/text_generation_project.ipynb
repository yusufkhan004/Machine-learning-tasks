{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_generation_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNd4GqI4KrG33bg4ZLwmah/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yusufkhan004/Machine-learning-tasks/blob/master/text%20generation/text_generation_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGNamGUqdWLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load data\n",
        "#loading data and opening our input data in th e form of text file\n",
        "#project Gutenburg/berg is where the data can be found(just Google it)\n",
        "file = open('thinkbayes.txt').read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vLLU2T3HoY5U",
        "outputId": "ea15c4a1-5dc0-4ad4-8d77-5d8e8b1a3ae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "#import independencies\n",
        "import numpy\n",
        "import sys\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras import Sequential  #For building the Neural Network layer by layer\n",
        "from tensorflow.keras.layers import Dense, Dropout,LSTM  # dense -->To randomly initialize the weights to small numbers close to 0(But not 0)\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEHvNdNxegNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokenization = process of breaking down a stream of text into a words,phrases or symbols or other such meaningful elements which are called tokens,\n",
        "#list of tokens become imputs for futher process suh as parsing or text mining. simply ,tokenization is a method to simplify content prior to the next step of processing it\n",
        "#before a tokenization of data we'll make all the words in lowercase in oreder to standardize it\n",
        "#standardization\n",
        "def tokenize_words(input):\n",
        "  input = input.lower()\n",
        "  tokenizer = RegexpTokenizer(r'\\w+') #instantiating a tokenizer\n",
        "  tokens = tokenizer.tokenize(input)  #\n",
        "  filtered = filter(lambda token: token not in stopwords.words('english'), tokens) #common words like a,the,an etc thay dont provide any meaning to the data we are going to use so we have to filter them using lambda method\n",
        "  return \"\".join(filtered)\n",
        "  \n",
        "processed_inputs = tokenize_words(file)  # we r going to preprocess the data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-NK-13puhSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " #chars to numbers\n",
        " #convert character in our input to numbers\n",
        " #we'll sort the list of the set of all characters that appears os out i/p text and then use the enumerate function to get numbers that reprsent the character\n",
        " #we'll then create a dictionary that stores the keys and valus , or the characters and the numbers that reresent them\n",
        " chars = sorted(list(set(processed_inputs)))\n",
        " chars_to_nums = dict((c,i) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RabVxnX8ybAm",
        "colab_type": "code",
        "outputId": "4394667c-31e7-41ff-ece2-ae7d71cd0304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#check if words to chars or chars to num(?!) has worked ?\n",
        "#just so we get an idea of whether our process of converting words to characters has worked\n",
        "#we print the length of the variables\n",
        "input_len = len(processed_inputs)\n",
        "vocab_len = len(chars)\n",
        "print('total numbers of characters:', input_len)\n",
        "print('total vocab:',vocab_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total numbers of characters: 173092\n",
            "total vocab: 46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BN4e0NGUzDji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sequence length\n",
        "#we're defining how long an individual sequence here\n",
        "#an individual sequence is a complete mapping of inputcharacteristtics as integers\n",
        "seq_length = 100\n",
        "x_data = []\n",
        "y_data = []\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XR8qAwgzZuX",
        "colab_type": "code",
        "outputId": "601f5c1b-fdf1-4877-d34d-6f7508e3197b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#loop through the sequence\n",
        "#here we're going through entire list of i/ps and converting char into nuberswith a for loop\n",
        "#tjis wiil create a bunch of sequences where each sequence start with the next characters is the i/p data\n",
        "#beginning with the first character\n",
        "for i in range(0,input_len - seq_length, 1):    \n",
        "  in_seq =processed_inputs[i:i + seq_length]  #define i/p and o/p sequence. input is the current character + desired sequence length\n",
        "  out_seq = processed_inputs[i + seq_length]  #out sequence is the iniial charcter + total sequence length\n",
        "  x_data.append([chars_to_nums[char] for char in in_seq])  #converting the lists of char to int based on previous alue and appending the values to our lists\n",
        "  y_data.append(chars_to_nums[out_seq])\n",
        "\n",
        "n_patterns = len(x_data)  #check to see how many total input sequence we have\n",
        "print(\"Total Patterns:\",n_patterns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns: 172992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPQY6LOA0qy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert input sequence to np array that our network can use\n",
        "X = numpy.reshape(x_data, (n_patterns, seq_length, 1))\n",
        "X = X/float(vocab_len)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTskhQth1Vaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one-hot encoding our label data\n",
        "y = np_utils.to_categorical(y_data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vy6OUN3u1i2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating the model\n",
        "#creating a sequential model\n",
        "#dropout is used to prevent ovrfitting\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJj11hihSdEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compile the model\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eYVIEMzSwqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#saving weights\n",
        "filepath = \"model_weights_saved.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose =1, save_best_only=True, mode='min')\n",
        "desired_callbacks= [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXuKQr5rTYJe",
        "colab_type": "code",
        "outputId": "4fa2ea74-b33b-4c31-e2c5-d0af7624d41a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "#fit model and let it train\n",
        "model.fit(X,y, epochs = 4, batch_size=254, callbacks=desired_callbacks)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "682/682 [==============================] - ETA: 0s - loss: 3.1259\n",
            "Epoch 00001: loss improved from inf to 3.12592, saving model to model_weights_saved.hdf5\n",
            "682/682 [==============================] - 2610s 4s/step - loss: 3.1259\n",
            "Epoch 2/4\n",
            "682/682 [==============================] - ETA: 0s - loss: 3.0778\n",
            "Epoch 00002: loss improved from 3.12592 to 3.07784, saving model to model_weights_saved.hdf5\n",
            "682/682 [==============================] - 2628s 4s/step - loss: 3.0778\n",
            "Epoch 3/4\n",
            "682/682 [==============================] - ETA: 0s - loss: 2.9708\n",
            "Epoch 00003: loss improved from 3.07784 to 2.97085, saving model to model_weights_saved.hdf5\n",
            "682/682 [==============================] - 2585s 4s/step - loss: 2.9708\n",
            "Epoch 4/4\n",
            "682/682 [==============================] - ETA: 0s - loss: 2.8685\n",
            "Epoch 00004: loss improved from 2.97085 to 2.86846, saving model to model_weights_saved.hdf5\n",
            "682/682 [==============================] - 2557s 4s/step - loss: 2.8685\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd1d4039208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSDJznyBdhRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#recompile module with thee saved weights\n",
        "filename = \"model_weights_saved.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzwACnaceN54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#output of the model back into characters\n",
        "num_to_char = dict((i,e) for i,e in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq82XDzIelcf",
        "colab_type": "code",
        "outputId": "6c90fbfc-dacd-4d3c-9154-50995d0dd4a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#random need to help generate\n",
        "start = numpy.random.randint(0, len(x_data) - 1)\n",
        "pattern = x_data[start]\n",
        "print(\"Random Seeds:\")\n",
        "print(\"\\\"\", ''.join([num_to_char[value] for value in pattern]), \"\\\"\")\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Seeds:\n",
            "\" ldifferentialpositivebruinswinnegativecanuckswin0tiep_windiffprobgreater0p_lossdiffprobless0p_tiedif \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wwQetNpfYqb",
        "colab_type": "code",
        "outputId": "27218459-cd82-4202-f4f8-109cf84d3a02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#generate the text\n",
        "for i in range (1000):\n",
        "  x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "  x = x/float(vocab_len)\n",
        "  prediction = model.predict(x, verbose=0)\n",
        "  index = numpy.argmax(prediction)\n",
        "  result = num_to_char[index]\n",
        "  seq_in =[num_to_char[value] for value in pattern]\n",
        "  sys.stdout.write(result)\n",
        "  pattern.append(index)\n",
        "  pattern = pattern[1:len(pattern)]\n",
        "  "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eoeeeoeeeateseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseeseseesesee"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BlmJUZ7hLrJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}